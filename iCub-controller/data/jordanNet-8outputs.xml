<!DOCTYPE nnfw-xml>
<nnfw version="1.1" >
  <neuralnet>
    <cluster numNeurons="100" type="BiasedCluster" name="Input" >
      <accumulate> false </accumulate>
      <inputs> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </inputs>
      <outputs> 0.298991 0.649694 0.702076 0.261814 0.52296 0.559116 0.692154 0.546071 0.607348 0.329187 0.562616 0.47272 0.714311 0.673522 0.675502 0.685354 0.711899 0.594839 0.425362 0.604574 0.303349 0.601933 0.677298 0.614535 0.552535 0.877224 0.733743 0.717971 0.443532 0.433618 0.492092 0.474444 0.633463 0.486072 0.488947 0.639758 0.336077 0.66866 0.488532 0.696409 0.552924 0.309682 0.686901 0.494259 0.307349 0.385376 0.459869 0.485858 0.717171 0.669834 0.585424 0.284572 0.760585 0.363327 0.413411 0.558833 0.330892 0.85119 0.421535 0.547022 0.37914 0.676903 0.531349 0.519854 0.433558 0.492406 0.423761 0.760853 0.270785 0.660626 0.529822 0.543079 0.523333 0.858786 0.582815 0.532648 0.596083 0.777609 0.309584 0.360764 0.509975 0.666569 0.412104 0.340967 0.27381 0.536112 0.709937 0.361145 0.49678 0.431924 0.640169 0.613687 0.409394 0.66539 0.39299 0.624024 0.461589 0.586642 0.436442 0.468207 </outputs>
      <outfunction type="SigmoidFunction" >
        <lambda> 1 </lambda>
      </outfunction>
      <biases> 0.852078 -0.617691 -0.857275 1.03656 -0.091954 -0.237597 -0.810231 -0.1848 -0.436104 0.71184 -0.251793 0.109294 -0.916423 -0.724198 -0.733208 -0.778525 -0.904604 -0.383905 0.300791 -0.424466 0.831424 -0.413581 0.258605 0.533574 0.788925 -0.966416 -0.0137364 0.0655227 0.226883 0.267087 0.0315295 0.1023 0.452971 0.0556006 0.0443702 -0.574351 0.680806 0.297785 0.045929 -0.830253 -0.212441 0.801541 0.214342 0.0230763 0.812574 0.466863 0.160991 1.05657 -0.930414 -0.707416 -0.345113 0.921925 -0.155882 0.56111 0.349894 -0.23651 0.704161 -0.743924 0.316422 -0.188537 0.493255 -0.739635 0.874433 -0.0795355 0.267546 0.030462 0.307433 -0.157374 0.990549 -0.666112 -0.119358 -0.172793 0.906519 -0.805242 0.665653 0.869152 0.610713 -0.251826 0.802095 0.572038 -0.0398875 -0.6927 0.355313 0.658971 0.975334 -0.144743 -0.895078 0.570348 0.0129476 0.273997 -0.576075 -0.462924 0.36661 -0.687392 0.434705 -0.506577 0.154012 -0.350007 0.255587 0.127447 </biases>
    </cluster>
    <cluster numNeurons="5" type="BiasedCluster" name="Hidden" >
      <accumulate> false </accumulate>
      <inputs> 5.42729 -4.19148 -1.70486 2.08559 2.18404 </inputs>
      <outputs> 0.996863 0.0434634 0.0753127 0.907417 0.950984 </outputs>
      <outfunction type="SigmoidFunction" >
        <lambda> 1 </lambda>
      </outfunction>
      <biases> -0.334039 -1.09978 0.803175 -0.196831 -0.781488 </biases>
    </cluster>
    <cluster numNeurons="8" type="SimpleCluster" name="Context" >
      <accumulate> false </accumulate>
      <inputs> 0 0 0 0 0 0 0 0 </inputs>
      <outputs> 0.553543 0.00643322 0.372707 0.378756 0.400586 0.414226 0.391949 0.454905 </outputs>
      <outfunction type="IdentityFunction" />
    </cluster>
    <cluster numNeurons="8" type="BiasedCluster" name="Output" >
      <accumulate> false </accumulate>
      <inputs> 2.3069 -3.809 0.676033 -0.45601 -0.359579 -0.0645804 -0.424704 -0.348969 </inputs>
      <outputs> 0.571955 0.00657554 0.388857 0.39601 0.420658 0.429851 0.407483 0.472784 </outputs>
      <outfunction type="SigmoidFunction" >
        <lambda> 1 </lambda>
      </outfunction>
      <biases> 2.0166 1.2088 1.12781 -0.0339746 -0.0398687 0.217582 -0.0508411 -0.240639 </biases>
    </cluster>
    <linker from="Input" type="DotLinker" to="Hidden" name="In2Hid" >
      <weights>
          -0.473413   -0.445431    -0.386198    0.201587     -0.459469
          -0.778801   -0.686591     0.870589   -0.542369     -0.380236
           0.347293    -0.17395    -0.894945    0.696687      0.758125
          -0.302017   -0.039092   -0.0615706    0.477013    -0.0482317
          -0.124243    -0.65344     0.140662     -0.7811     -0.155769
          -0.175984   -0.610739     0.346865    0.832873      0.182879
          -0.863334   -0.563451     0.779413   -0.402512      0.471557
          -0.606721   -0.187379     0.784004   -0.878948      0.152511
          -0.477122    0.452345     0.947068   -0.541027     0.0321987
           0.797394    0.181583    -0.976109   -0.342451     -0.417579
          0.0681536    0.543097   -0.0801069   -0.934632      0.622438
           0.849262    -0.12678       1.0023   0.0711595     -0.369217
           0.332579    0.218127    0.0302284  -0.0715695      0.653699
          -0.366352    0.155511    -0.478222    -0.79689       0.30724
           0.766338   -0.404191    -0.183514    0.498565      0.101723
           0.942646     0.21854    -0.632332    0.762225      0.901707
          0.0288217   -0.269251     0.490052    0.719628     -0.178565
           0.211771    0.635243     0.715081   0.0778855     -0.398071
          -0.582072   -0.621973     0.768437    0.315145      0.222478
           0.567901    0.928507    -0.468136    0.895627     -0.922019
           0.938729    0.612153    -0.177704   -0.371951      0.103639
            1.06966    -0.67559    -0.492761   -0.808405     -0.767544
          -0.481164    -0.44995    0.0628502     1.09163     0.0314152
            1.06444   -0.415368    -0.574281    0.986569     -0.847017
           0.225137    -1.34642    -0.709697    0.213574      0.419312
           0.752089   -0.795832      0.16128   -0.685919      -0.70933
           0.406851    -1.30217     0.781622   -0.599809     -0.282069
          0.0899665    -1.50134    0.0854733    0.656487     -0.603771
           0.476523     0.60863     0.556925   -0.582438      0.610283
           -0.48423   -0.464148    -0.360965  -0.0657288      -0.90162
          -0.250968    -0.81968    -0.825739  0.00897802     -0.070903
           0.554203   -0.564247     0.404002   -0.424036     -0.292329
           0.707378    0.575784    -0.316279    0.778708     -0.849537
            0.49125   -0.480775     -0.84855   -0.493777      0.773641
          -0.455192     1.14226     0.794961    0.890282    -0.0989791
           0.467198   -0.409448   0.00634893    0.922245      0.643083
           0.067203   -0.332579     0.421138    0.138191      0.599718
           -0.51426   -0.714019    -0.789522     1.04366      0.346395
           0.108867    0.134688     0.274594    0.710776     -0.248411
           0.378014    0.119523     0.290339    0.299815      0.645226
           0.155965    0.623703     0.699334   -0.347493      0.646091
          -0.903509   -0.889637    -0.913675  -0.0855948      -1.02175
           0.475146     0.58639    -0.446372   0.0896058      0.162943
          -0.653555    0.904707     0.794603   -0.753664     -0.292888
        -0.00853692     1.14128    -0.809206    -1.08153     -0.360773
          0.0429277      1.0752    -0.489096    -1.05206     -0.901181
          -0.664925     1.06251    -0.305168    0.594182      -1.14297
           -0.61332    0.563653     -0.99436   -0.306668    -0.0665598
          -0.801258    0.861396    -0.180079   -0.325537     -0.530858
           0.971702   -0.151375     0.747455    0.489152      0.402258
          -0.340626   -0.614726     0.075051   -0.301002     -0.341303
          -0.607973    0.534669    -0.784068    -0.19873      -1.02899
          0.0953797   -0.161604     0.239519     0.86334      0.063157
           0.375109     1.68534  0.000806609   0.0877262     -0.873139
           0.867302    0.692087    -0.822152   -0.482604     -0.340895
          -0.307457   -0.358069     0.245217   -0.775613        1.3392
          -0.372133    0.599602    -0.420787    0.282775      0.399853
           0.356225    0.840533     0.402561    0.562741      0.187187
           0.422626   -0.872412     0.969447    -0.43803      0.863633
         -0.0112676    0.763935     0.873155    0.736111      0.274581
          -0.842308    0.626883    -0.199056   -0.882689     -0.912835
          0.0491132   -0.398077    -0.416145    -1.03297     -0.139205
          -0.454312    -1.06077     0.685549    0.203659     -0.740247
           0.400106  -0.0715103    -0.825685   -0.618358       0.32661
         -0.0615337     1.77511     0.937942   -0.532367     -0.524882
           0.860291     1.41929    -0.319943     0.30595      0.286841
           0.983729     1.47562      0.14204   -0.604434      0.623668
           0.271652    0.335091    -0.548236    0.948067      0.700057
            0.47317    -1.09146    -0.710144   0.0895548     0.0410516
          -0.493959   -0.431146     0.272061   -0.553809     0.0520841
          -0.172883    0.388705      0.13645   -0.431488     -0.964884
           0.839111   -0.557903     0.758281   -0.687032      0.872462
           0.257589    -1.40855      0.56759   -0.526528   -0.00533787
           0.548068   0.0310975    -0.470352     1.06117     0.0540681
          -0.746285   -0.328592     0.131716   -0.339162     -0.423272
          -0.670813   -0.844303   -0.0862498    0.734551       0.34264
          -0.843364     -1.4277    -0.459835    0.438328     -0.117307
          -0.235407   -0.592903     0.144584   -0.417493      0.296657
           0.136896    0.588062     0.499299   -0.315597      0.729565
          -0.553266   -0.841567     0.148406   -0.104565      -1.01578
          -0.742385    0.151631     0.367417    0.325054      0.425872
           0.935467    0.692608    -0.690135    -0.24239    0.00847044
           0.591805   -0.101328     0.308004   -0.915046      -1.00771
          -0.849751   -0.205587   -0.0359148    0.235505     0.0679757
          -0.760149   -0.622976    -0.342649    0.662117   -0.00260158
           -0.50703   -0.855876     0.156005    0.518226    -0.0834368
           0.250523    0.813958    -0.917932   -0.551515    -0.0236551
            0.56615   -0.646811    -0.343427    0.759185     0.0354186
           0.788587    0.364896     0.935838  -0.0200794      0.352052
           0.999471    0.151598    -0.844973   -0.142636     -0.704206
           0.335894    0.159831    -0.303476    0.848596     -0.316306
           0.788203   -0.625403    -0.165323   -0.205518      0.735623
            0.81797    0.990186     0.518825    0.768538       -0.6043
          -0.335701    0.390631    -0.257035     0.16792  -4.56418e-05
           0.835984  -0.0385958    -0.616472    0.668049      0.840407
           0.845845    0.693304   0.00173918    0.850463     -0.563487
           0.382596    0.164718     0.557795    0.950943     -0.059935
           -0.62914    0.732388     0.265295   0.0423421     -0.578063
           0.113641   -0.119888    -0.567533   -0.463826     -0.447144
          -0.108306    0.161246     0.895615    0.497992     -0.731576
      </weights>
    </linker>
    <linker from="Context" type="DotLinker" to="Hidden" name="Cont2Hid" >
      <weights>
         -0.123222   -0.908388  -0.963048  -0.364745    1.2981
         0.0291638  -0.0457075   -1.69916   -1.85579  0.544552
        0.00251528   -0.423696   -1.97368   -1.00105   1.22355
        -0.0367498    -1.58604  0.0430188  -0.805871   1.99981
          0.347821  -0.0743072   -2.48648  -0.506957   2.23356
          0.308301    -1.68267  -0.121643   0.322145  0.477263
          0.178054    -1.74095    0.51817  -0.384982  0.950508
         -0.599503   -0.526648  -0.365522    0.25533   1.34112
      </weights>
    </linker>
    <linker from="Hidden" type="DotLinker" to="Output" name="Hid2Out" >
      <weights>
         -1.13626  -2.47163  -0.654033  -0.361684  -0.858434  -0.943855  -0.709514    0.372636
        0.0736886    3.3293  -0.246781    -2.6858   0.620309   -5.00609   -4.63483    -5.25451
         -1.23074  -1.81889   -1.71011   0.259323   -2.72765   0.637863   -1.26205   -0.997923
         0.290877  -2.34458  -0.595292   -2.10327   -1.58115  -0.109727   0.543638   -0.428747
          3.43479  0.814586    2.11216    2.00897    2.21915    1.20531  0.0916741  -0.0274372
      </weights>
    </linker>
    <linker from="Output" type="CopyLinker" to="Context" name="Out2Cont" >
      <mode> Out2In </mode>
    </linker>
    <inputs>Input </inputs>
    <outputs>Output </outputs>
    <order>Input In2Hid Context Cont2Hid Hidden Hid2Out Output Out2Cont </order>
  </neuralnet>
</nnfw>
